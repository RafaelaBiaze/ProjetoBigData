{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe57fcb-248b-407e-a4c3-86bda548b60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando dados tratados no HDFS (Silver)...\n",
      "Dados Silver salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ETL_02_Silver\").getOrCreate()\n",
    "\n",
    "# --- 3. Transformação (Transform) ---\n",
    "schema = StructType([\n",
    "    StructField(\"Id\", IntegerType(), True),\n",
    "    StructField(\"IndicatorCode\", StringType(), True),\n",
    "    StructField(\"SpatialDimType\", StringType(), True),\n",
    "    StructField(\"SpatialDim\", StringType(), True),\n",
    "    StructField(\"ParentLocationCode\", StringType(), True),\n",
    "    StructField(\"TimeDimType\", StringType(), True),\n",
    "    StructField(\"ParentLocation\", StringType(), True),\n",
    "    StructField(\"Dim1Type\", StringType(), True),\n",
    "    StructField(\"TimeDim\", IntegerType(), True),\n",
    "    StructField(\"Dim1\", StringType(), True),\n",
    "    StructField(\"Dim2Type\", StringType(), True),\n",
    "    StructField(\"Dim2\", StringType(), True),\n",
    "    StructField(\"Dim3Type\", StringType(), True),\n",
    "    StructField(\"Dim3\", StringType(), True),\n",
    "    StructField(\"DataSourceDimType\", StringType(), True),\n",
    "    StructField(\"DataSourceDim\", StringType(), True),\n",
    "    StructField(\"Value\", StringType(), True),\n",
    "    StructField(\"NumericValue\", DoubleType(), True),\n",
    "    StructField(\"Low\", DoubleType(), True),\n",
    "    StructField(\"High\", DoubleType(), True),\n",
    "    StructField(\"Comments\", StringType(), True),\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"TimeDimensionValue\", StringType(), True),\n",
    "    StructField(\"TimeDimensionBegin\", StringType(), True),\n",
    "    StructField(\"TimeDimensionEnd\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Função Adaptada para ler do HDFS Bronze\n",
    "def processar_silver(nome_dataset):\n",
    "    caminho_bronze = f\"hdfs://namenode:9000/datalake/bronze/{nome_dataset}\"\n",
    "    \n",
    "    # Lê o JSON da Bronze aplicando o Schema\n",
    "    df = spark.read.schema(schema).json(caminho_bronze)\n",
    "    \n",
    "    # Aplicando transformações\n",
    "    df_tratado = df.select(\n",
    "        col(\"SpatialDim\").alias(\"Pais\"),\n",
    "        col(\"TimeDim\").alias(\"Ano\"),\n",
    "        col(\"Dim1\").alias(\"Sexo\"),\n",
    "        col(\"NumericValue\").alias(\"Valor\")\n",
    "    )\n",
    "    return df_tratado\n",
    "\n",
    "# Processamento\n",
    "df_suicidio_b = processar_silver(\"suicidio_b\")\n",
    "df_suicidio_f = processar_silver(\"suicidio_f\")\n",
    "df_suicidio_m = processar_silver(\"suicidio_m\")\n",
    "df_depressao_b = processar_silver(\"depressao_b\")\n",
    "df_depressao_f = processar_silver(\"depressao_f\")\n",
    "df_depressao_m = processar_silver(\"depressao_m\")\n",
    "\n",
    "# --- 4. Carga (Load) ---\n",
    "# O caminho no HDFS onde os dados serão salvos.\n",
    "print(f\"Salvando dados tratados no HDFS (Silver)...\")\n",
    "\n",
    "df_suicidio_b.write.mode(\"overwrite\").parquet(\"hdfs://namenode:9000/datalake/silver/suicidio_b\")\n",
    "df_suicidio_f.write.mode(\"overwrite\").parquet(\"hdfs://namenode:9000/datalake/silver/suicidio_f\")\n",
    "df_suicidio_m.write.mode(\"overwrite\").parquet(\"hdfs://namenode:9000/datalake/silver/suicidio_m\")\n",
    "\n",
    "df_depressao_b.write.mode(\"overwrite\").parquet(\"hdfs://namenode:9000/datalake/silver/depressao_b\")\n",
    "df_depressao_f.write.mode(\"overwrite\").parquet(\"hdfs://namenode:9000/datalake/silver/depressao_f\")\n",
    "df_depressao_m.write.mode(\"overwrite\").parquet(\"hdfs://namenode:9000/datalake/silver/depressao_m\")\n",
    "\n",
    "print(\"Dados Silver salvos com sucesso!\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78c1dd-8ef4-4f20-90f1-37c8334bef7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
