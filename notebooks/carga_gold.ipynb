{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e88028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import os\n",
    "\n",
    "# --- 1. Configuração do Spark e Variáveis ---\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GoldLayerModelingOptimized\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SILVER_PATH = 'hdfs://namenode:9870/datalake/silver/who_data_silver.parquet'\n",
    "GOLD_PATH = 'hdfs://namenode:9870/datalake/gold/correlation_ready_data.parquet'\n",
    "\n",
    "def load_silver_data(path):\n",
    "    \"\"\"Carrega os dados limpos da camada Silver do HDFS.\"\"\"\n",
    "    print(f\"Lendo dados limpos de: {path}\")\n",
    "    try:\n",
    "        df_silver = spark.read.parquet(path)\n",
    "        return df_silver\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao ler o Parquet em {path}: {e}\")\n",
    "        return spark.createDataFrame([], schema=None)\n",
    "\n",
    "def transform_to_gold(df_silver):\n",
    "    \"\"\"Pivotar os dados para o modelo final (wide format).\"\"\"\n",
    "    if df_silver.count() == 0:\n",
    "        return spark.createDataFrame([], schema=None)\n",
    "\n",
    "    print(\"Iniciando modelagem Gold Otimizada (Pivotagem)...\")\n",
    "\n",
    "    # Pivotagem direta. Usamos 'first' como função de agregação,\n",
    "    # pois não deve haver duplicatas no Silver (após o filtro por BOTHSEXES)\n",
    "    df_gold = df_silver.groupBy(\"Country_Code\", \"Year\").pivot(\"Indicator_Name\").agg(col(\"Value\").alias(\"first\"))\n",
    "\n",
    "    # Os nomes das colunas são os nomes dos indicadores\n",
    "    df_gold = df_gold.filter(\n",
    "        col(\"Taxa_Mortalidade_Suicidio\").isNotNull() & \n",
    "        col(\"Prevalencia_Transtorno_Humor\").isNotNull()\n",
    "    )\n",
    "    \n",
    "    print(f\"Modelagem Gold concluída. Total de linhas prontas para correlação: {df_gold.count()}\")\n",
    "    return df_gold\n",
    "\n",
    "def save_gold_data(df_gold, file_path):\n",
    "    \"\"\"Salva o DataFrame final no formato Parquet no HDFS.\"\"\"\n",
    "    if df_gold.count() > 0:\n",
    "        print(f\"Salvando dados agregados (Camada Gold) em: {file_path}\")\n",
    "        df_gold.write.mode(\"overwrite\").parquet(file_path)\n",
    "        print(\"Dados salvos com sucesso!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_silver = load_silver_data(SILVER_PATH)\n",
    "    if df_silver.count() > 0:\n",
    "        df_gold = transform_to_gold(df_silver)\n",
    "        save_gold_data(df_gold, GOLD_PATH)\n",
    "    else:\n",
    "        print(\"O processamento Gold não pode ser executado, pois a camada Silver está vazia.\")\n",
    "    \n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
