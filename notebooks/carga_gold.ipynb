{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e74e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "import os\n",
    "\n",
    "# --- 1. Configuração do Spark e Variáveis ---\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GoldLayerModeling\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "SILVER_PATH = 'hdfs://namenode:9870/datalake/silver/who_data_silver.parquet'\n",
    "GOLD_PATH = 'hdfs://namenode:9870/datalake/gold/correlation_ready_data.parquet'\n",
    "\n",
    "\n",
    "def load_silver_data(path):\n",
    "    \"\"\"Carrega os dados limpos da camada Silver do HDFS.\"\"\"\n",
    "    print(f\"Lendo dados limpos de: {path}\")\n",
    "    try:\n",
    "        # Lê o Parquet otimizado\n",
    "        df_silver = spark.read.parquet(path)\n",
    "        return df_silver\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao ler o Parquet em {path}: {e}\")\n",
    "        return spark.createDataFrame([], schema=None)\n",
    "\n",
    "\n",
    "def transform_to_gold(df_silver):\n",
    "    \"\"\"Pivotar os dados para o modelo final (wide format).\"\"\"\n",
    "    if df_silver.count() == 0:\n",
    "        return spark.createDataFrame([], schema=None)\n",
    "\n",
    "    print(\"Iniciando agregação e modelagem (Camada Gold)...\")\n",
    "\n",
    "    # A pivotagem no PySpark é mais limpa usando o agrupamento (groupBy)\n",
    "    df_gold = df_silver.groupBy(\"Country_Code\", \"Year\").pivot(\"Indicator_Name\").agg({\"Value\": \"mean\"})\n",
    "\n",
    "    # Renomear colunas para garantir consistência (se os nomes gerados pelo pivot forem complexos)\n",
    "    # Neste caso, os nomes devem ser os mapeados na Silver:\n",
    "    # 'Taxa_Mortalidade_Suicidio' e 'Prevalencia_Transtorno_Humor'\n",
    "\n",
    "    # 1. Tratar possíveis Nulos na pivotagem (países que só têm um indicador)\n",
    "    df_gold = df_gold.na.drop(subset=['Taxa_Mortalidade_Suicidio', 'Prevalencia_Transtorno_Humor'])\n",
    "    \n",
    "    print(f\"Modelagem Gold concluída. Total de linhas prontas para correlação: {df_gold.count()}\")\n",
    "    return df_gold\n",
    "\n",
    "\n",
    "def save_gold_data(df_gold, file_path):\n",
    "    \"\"\"Salva o DataFrame final no formato Parquet no HDFS.\"\"\"\n",
    "    if df_gold.count() > 0:\n",
    "        print(f\"Salvando dados agregados (Camada Gold) em: {file_path}\")\n",
    "        # Salvar em formato Parquet\n",
    "        df_gold.write.mode(\"overwrite\").parquet(file_path)\n",
    "        print(\"Dados salvos com sucesso!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_silver = load_silver_data(SILVER_PATH)\n",
    "    if df_silver.count() > 0:\n",
    "        df_gold = transform_to_gold(df_silver)\n",
    "        save_gold_data(df_gold, GOLD_PATH)\n",
    "    else:\n",
    "        print(\"O processamento Gold não pode ser executado, pois a camada Silver está vazia.\")\n",
    "    \n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
