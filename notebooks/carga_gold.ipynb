{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628eb9aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, first\n",
    "\n",
    "# 1. Iniciando a Sessão Spark\n",
    "# SparkSession: É o ponto de entrada. Sem ele, nada acontece.\n",
    "# .master(...): Diz quem manda. 'spark://spark-master:7077' é o endereço do container mestre.\n",
    "# .config(...defaultFS...): Ensina o Spark que, quando eu falar \"/pasta\", é no HDFS, não no local.\n",
    "# .config(...hive...): Habilita suporte a salvar tabelas SQL.\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL_Silver\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def carga_gold():\n",
    "    print(\"Iniciando Camada Gold...\")\n",
    "    \n",
    "    # 1. Leitura Otimizada\n",
    "    # Lemos Parquet, não JSON. É muito mais rápido.\n",
    "    df_suicidio = spark.read.parquet(\"/datalake/silver/raw_suicidio\")\n",
    "    df_depressao = spark.read.parquet(\"/datalake/silver/raw_depressao\")\n",
    "    \n",
    "    # 2. Join (Cruzamento)\n",
    "    # on=[\"Pais\", \"Ano\"]: A chave da junção.\n",
    "    # how=\"inner\": Só mantém países que tenham dados AMBOS de suicídio e depressão.\n",
    "    df_gold = df_suicidio.join(df_depressao, on=[\"Pais\", \"Ano\"], how=\"inner\")\n",
    "    \n",
    "    # 3. Salvar Tabela Hive (Para o Superset)\n",
    "    # saveAsTable: Registra os metadados no Hive Metastore.\n",
    "    # Isso permite fazer SQL: \"SELECT * FROM saude_mental_analitica\" no Trino/Superset.\n",
    "    df_gold.write.mode(\"overwrite\").saveAsTable(\"saude_mental_analitica\")\n",
    "    print(\"✅ Tabela Hive 'saude_mental_analitica' disponível para SQL!\")\n",
    "\n",
    "    # 4. Salvar CSV (Para Download/Power BI)\n",
    "    # coalesce(1): O Spark divide arquivos (sharding). Isso força ele a juntar tudo em 1 arquivo só.\n",
    "    # option(\"header\", \"true\"): Escreve o cabeçalho no CSV.\n",
    "    df_gold.coalesce(1).write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(\"/datalake/gold/analise_final_csv\")\n",
    "        \n",
    "    print(\"✅ CSV gerado em /datalake/gold/analise_final_csv\")\n",
    "\n",
    "    # Comando de sistema (Shell) para pegar o arquivo do HDFS\n",
    "    # getmerge: Pega a pasta do HDFS (/datalake/...) e junta num arquivo local\n",
    "    # O destino deve ser a pasta que está sincronizada com seu Windows (/home/jovyan/data)\n",
    "    exit_code = os.system(\"hdfs dfs -getmerge /datalake/gold/analise_final_csv /home/jovyan/notebooks/datasets/resultado_powerbi.csv\")\n",
    "\n",
    "    if exit_code == 0:\n",
    "        print(\"✅ Arquivo 'resultado_powerbi.csv' gerado com sucesso na sua pasta local!\")\n",
    "    else:\n",
    "        print(\"❌ Erro ao exportar o arquivo.\")\n",
    "    \n",
    "# Rodando a finalização\n",
    "carga_gold()\n",
    "spark.stop()\n",
    "print(\"Sessão Spark finalizada.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
